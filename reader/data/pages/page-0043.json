{
  "page": 43,
  "title": "3.1 Asymptotic Notation",
  "content": "<div class=\"article-header\">\n    <div class=\"section-label\">Section 3.1</div>\n    <h1>Asymptotic Notation</h1>\n</div>\n<div class=\"original-content\">\n    <div class=\"definition-box\">\n        <h4>Summary</h4>\n        <p><strong>Mathematical notation for describing algorithm growth rates: O, Θ, Ω, o, ω.</strong></p>\n    </div>\n\n    <div class=\"highlight-box\">\n        <h4>Key Points</h4>\n        <ul><li>O(g(n)): grows at most as fast as g(n) - upper bound</li>\n<li>Ω(g(n)): grows at least as fast as g(n) - lower bound</li>\n<li>Θ(g(n)): grows exactly as fast as g(n) - tight bound</li>\n<li>o(g(n)): grows strictly slower than g(n)</li>\n<li>ω(g(n)): grows strictly faster than g(n)</li></ul>\n    </div>\n\n    \n    <div class=\"figure-box\">\n    <h4>Example</h4>\n    <p>2n² + 3n + 1 = Θ(n²) because it&#x27;s both O(n²) and Ω(n²). The constants (2, 3, 1) don&#x27;t matter for large n.</p>\n</div>\n    <div class=\"highlight-box\">\n    <h4>Why It Matters</h4>\n    <p>Asymptotic notation lets us compare algorithms independent of hardware or implementation details.</p>\n</div>\n</div>"
}