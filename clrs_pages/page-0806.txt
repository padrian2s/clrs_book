27.1 The basics of dynamic multithreading                                        785


value for n sufﬁces to achieve near perfect linear speedup for P-F IB .n/, because
this procedure exhibits considerable parallel slackness.

Parallel loops
Many algorithms contain loops all of whose iterations can operate in parallel. As
we shall see, we can parallelize such loops using the spawn and sync keywords,
but it is much more convenient to specify directly that the iterations of such loops
can run concurrently. Our pseudocode provides this functionality via the parallel
concurrency keyword, which precedes the for keyword in a for loop statement.
  As an example, consider the problem of multiplying an n n matrix A D .aij /
by an n-vector x D .xj /. The resulting n-vector y D .yi / is given by the equation
       X
       n
yi D          aij xj ;
       j D1

for i D 1; 2; : : : ; n. We can perform matrix-vector multiplication by computing all
the entries of y in parallel as follows:

M AT-V EC .A; x/
1 n D A:rows
2 let y be a new vector of length n
3 parallel for i D 1 to n
4      yi D 0
5 parallel for i D 1 to n
6      for j D 1 to n
7           yi D yi C aij xj
8 return y

In this code, the parallel for keywords in lines 3 and 5 indicate that the itera-
tions of the respective loops may be run concurrently. A compiler can implement
each parallel for loop as a divide-and-conquer subroutine using nested parallelism.
For example, the parallel for loop in lines 5–7 can be implemented with the call
M AT-V EC -M AIN -L OOP .A; x; y; n; 1; n/, where the compiler produces the auxil-
iary subroutine M AT-V EC -M AIN -L OOP as follows:
